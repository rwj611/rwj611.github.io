---
layout:     post
title:      "Faiss"
subtitle:   "向量检索"
date:       2020-11-18 22:00:00
author:     "rwj611"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - ai
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        });
    </script>
</head>

#### overview

#### 1. faiss参数介绍

1. batch_size: batch size for trainning
2. nlist: the number for Voronoi cells
3. nprobe: the number of cells that are visited to perform a search

#### 2. CPU与GPU对比

假设xq为待查询向量
index为索引

1. xq的batch很小，Index很小： CPU通常更快；
2. xq的batch很小，Index很大： GPU通常更快；
3. xq的batch很大，Index很小：随便；
4. xq的batch很大，Index很大：GPU通常更快；
GPU通常比CPU快5到10倍；

#### 3. Faiss的骚操作一：PQ
节省内存

IndexFlatL2的暴力L2距离匹配是最基本的用法。
很快你就会遇到一个问题，当特征库很大的时候，一个显存就很快装载不下特征库了；
即使是换成使用内存来装载特征库，也装载不下了。
有没有一种压缩算法能减小特征库的大小呢？这就是PQ（Product Quantizer）

不管是IndexFlatL2、IndexIVFFlat、或者名字中包含有Flat的Index，都会在加载到内存中的特征库中保存全量的特征，
以2048维的float类型为例，一个样本就需要8192个字节。
如果类似天猫京东这样有1亿件商品，每件商品就按照一个样本图片来算，也需要...763G的特征库。
PQ就是一种有损压缩，所以这种Index进行检索的返回值只是近似的准确，而不是像IndexFlatL2那样可以返回绝对准确的值。

PQ是如何将一个样本的8192字节压缩的更小的呢？
假设我们有100万个样本，每个样本有2048维特征（100万 x 2048）
1. 我们将每个样本的2048维vector拆分为8个sub-vector，每个sub-vector就是256维了。这样就会有8个100万x256维的矩阵
2. 我们在这8个矩阵上使用k = 256的k-means 聚类算法（Gemfield：这里的256和上面的256没啥关系），这样每个矩阵上会得到256个centroid（质心），一共有8组256个centroid；聚类算法的使用，使得每个256维的centroid成为最能代表那3906个256维特征的一个向量（100w/256 = 3906）；为啥选择k=256呢？因为256个centroid的索引可以使用一个字节装下

#### 4. Faiss的骚操作二：IVF
加速检索

