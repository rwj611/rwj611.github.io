---
layout:     post
title:      "Faiss"
subtitle:   "向量检索"
date:       2020-11-18 22:00:00
author:     "rwj611"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - ai
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        });
    </script>
</head>

#### overview

#### 1. faiss参数介绍

1. batch_size: batch size for trainning
2. nlist: the number for Voronoi cells
3. nprobe: the number of cells that are visited to perform a search

#### 2. CPU与GPU对比

假设xq为待查询向量
index为索引

1. xq的batch很小，Index很小： CPU通常更快；
2. xq的batch很小，Index很大： GPU通常更快；
3. xq的batch很大，Index很小：随便；
4. xq的batch很大，Index很大：GPU通常更快；
GPU通常比CPU快5到10倍；

#### 3. Faiss的骚操作一：PQ
节省内存

IndexFlatL2的暴力L2距离匹配是最基本的用法。
很快你就会遇到一个问题，当特征库很大的时候，一个显存就很快装载不下特征库了；
即使是换成使用内存来装载特征库，也装载不下了。
有没有一种压缩算法能减小特征库的大小呢？这就是PQ（Product Quantizer）

不管是IndexFlatL2、IndexIVFFlat、或者名字中包含有Flat的Index，都会在加载到内存中的特征库中保存全量的特征，
以2048维的float类型为例，一个样本就需要8192个字节。
如果类似天猫京东这样有1亿件商品，每件商品就按照一个样本图片来算，也需要...763G的特征库。
PQ就是一种有损压缩，所以这种Index进行检索的返回值只是近似的准确，而不是像IndexFlatL2那样可以返回绝对准确的值。

PQ是如何将一个样本的8192字节压缩的更小的呢？
假设我们有100万个样本，每个样本有2048维特征（100万 x 2048）
1. 我们将每个样本的2048维vector拆分为8个sub-vector，每个sub-vector就是256维了。这样就会有8个100万x256维的矩阵
2. 我们在这8个矩阵上使用k = 256的k-means 聚类算法（Gemfield：这里的256和上面的256没啥关系），这样每个矩阵上会得到256个centroid（质心），一共有8组256个centroid；
   聚类算法的使用，使得每个256维的centroid成为最能代表那3906个256维特征的一个向量（100w/256 = 3906）；
   为啥选择k=256呢？因为256个centroid的索引可以使用一个字节装下
3. 我们再回到那1亿个商品的特征库，将每个商品的2048维特征拆分成8个sub-vector，
   每一个sub-vector都被替换为距离最近的那个centroid，并使用该centroid的id来表示（1个字节！）。
   如此以来，2048维特征就被替换成了8个centroid ID，也就是8个字节！如此以来，商品特征库就从763G下降到了0.745G

内存的使用量确实降下来了，但是如果特征库只包含centroid ID的话，怎么进行向量的相似度计算呢？
1. 一个2048维的xq来了，将该xq vector拆分为8个sub-vector；
2. xq vector的每个sub-vector就和8x256的centroid中对应的那组1x256的centroid进行L2距离计算，得到256个距离；
3. 上述的8组256个L2的距离，可以看成是一个表：256行x8列（毕竟是一个样本的特征被拆分了8个sub vector，所以不是8x256而是256x8）；这个表很重要啊，我暂且称之为gemfield表
4. 每个特征库的样本（每个xb记录）和xq的L2距离，就等于每个xb记录的8个sub-vector和xq的8个sub-vector的L2距离之和，
   就约等于xb记录的8个centroid（中的每个）和xq的8个sub-vector（中的每个）的L2距离之和！
   而xb记录的8个centorid中的每个和xq的8个sub-vector中的每个之间的L2距离，直接通过上述的gemfield表查表获得
5. 将距离排序，取得距离最近的k个xb记录（的index和distance）

上面的centroid（最类中心的那个2048维向量），在Faiss中我们称之为code；上述的8组256个centroid，在Faiss中我们称之为8个code book；这8个code book可以表达256^8个值，还是很大的

#### 4. Faiss的骚操作二：IVF
加速检索

如何更快检索
1. 两两特征比对更少的计算量；PQ顺带着做了；
2. 只和特征库的一部分进行比对；和特征库的每一个特征进行比对，叫做穷举；只和部分特征进行比对，叫做IVF；

什么是IVF
1. 在Faiss中所有带有IVF的index，
   指的都是提前将数据库使用k-means聚类算法划分为多个partition，
   每个partition中包含有对应的feature vectors（这就是inverted file lists指向的），
   同时，每个partition还有对应的centroid，用来决定该partition是应该被穷举搜索，还是被忽略。

2. 假如xq是落在partition的边缘地带，那这个xq最近的记录大概率是距离它最近（这个最近指的是和centroid比较）的前面好多个partition里的一个，
   这样即使我们指定很多个比较近的partition（比如5个），如果ground truth实际上是在第6个partition里，这样返回的结果依然是不准确的。

因此，带有IVF的检索只能返回近似正确的值，而不能像IndexFlatL2那样返回绝对正确的值。
但是像上面这种ground truth是在第6个partition里，而我们指定5个partition也是比指定1个partition要更准确些的（代价就是检索时间多了）。
一旦找到最近的那个partition后，便就要开始穷举检索该partition里的每条记录了，这就是IndexIVFFlat的由来。
在某个partition中进行搜索的过程还可以使用上一节的PQ压缩的算法，因此，在Faiss中，我们还经常会使用的一个Index叫作IndexIVFPQ。

